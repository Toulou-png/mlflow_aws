En tant qu'assistant IA, je peux g√©n√©rer un fichier **README.md** complet pour votre projet **`mlflow_aws`** bas√© sur les fichiers Python, JSON et Bash que vous avez fournis.

## üß† Projet : Pipeline ML Aynid sur AWS avec MLflow et Observabilit√©

Ce projet impl√©mente un pipeline d'apprentissage automatique (Machine Learning - ML) pour la **pr√©diction d'abandon de panier** pour la soci√©t√© fictive Aynid. L'infrastructure est d√©ploy√©e sur **AWS** et utilise **MLflow** pour le suivi des exp√©riences et **Prometheus/Grafana** pour l'observabilit√©. Une API **FastAPI** permet l'entra√Ænement et la pr√©diction, et une interface **Streamlit** offre un tableau de bord convivial.

-----

### üìÇ Structure du Projet

```
mlflow_aws/
‚îú‚îÄ‚îÄ api_pipeline.py            # API FastAPI pour le pipeline ML (Entra√Ænement & Pr√©diction)
‚îú‚îÄ‚îÄ aynid_pipeline.py          # Logique du pipeline ML (Pr√©paration des donn√©es, Entra√Ænement, Logging)
‚îú‚îÄ‚îÄ mlflow_aws.py              # Configuration AWS/MLflow/Postgres (similaire √† aynid_pipeline.py, contient aussi des plots)
‚îú‚îÄ‚îÄ mlflow_cg.sh               # Script Bash pour l'export des variables d'environnement MLflow
‚îú‚îÄ‚îÄ aynid_ml_dashboard.json    # Tableau de bord Grafana pour le monitoring Prometheus
‚îú‚îÄ‚îÄ streamlit_app.py           # Interface utilisateur Streamlit pour interagir avec l'API
‚îú‚îÄ‚îÄ requirements.txt           # D√©pendances Python
‚îî‚îÄ‚îÄ test_customer_data.csv     # Exemple de donn√©es client (g√©n√©r√©es mais incluses pour r√©f√©rence)
```

-----

### üöÄ D√©marrage Rapide

#### prerequisites

  * Compte AWS avec acc√®s aux services **S3** et **RDS (PostgreSQL)**.
  * Instance **EC2** pour h√©berger le serveur MLflow et le serveur Prometheus/Grafana.
  * **Docker** et **Docker Compose** (si utilisation d'une approche conteneuris√©e).
  * **Python 3.10+** avec les d√©pendances list√©es dans `requirements.txt`.

#### üõ†Ô∏è Configuration des Environnements

Le script `mlflow_cg.sh` contient les configurations principales. **Mettez √† jour** les variables d'environnement suivantes avec vos propres valeurs :

```bash
# mlflow_cg.sh (√† adapter)
export MLFLOW_S3_ENDPOINT_URL=https://s3.eu-west-3.amazonaws.com # R√©gion S3
export AWS_ACCESS_KEY_ID=AWS_ACCESS_KEY_ID # Cl√© d'acc√®s AWS
export AWS_SECRET_ACCESS_KEY=AWS_SECRET_ACCESS_KEY # Cl√© secr√®te AWS
export BACKEND_URI=postgresql://postgres:Pida2025@mlflow-postgre-db.c09u0wy6mlax.us-east-1.rds.amazonaws.com:5432/mlflow # Connexion PostgreSQL
export ARTIFACT_URI=s3://mlflow-artefacts-aynid # Nom du bucket S3
export MLFLOW_TRACKING_URI="http://3.85.105.94:5000" # IP/Port de l'instance MLflow
```

Sourcez le script : `source mlflow_cg.sh`

#### ‚öôÔ∏è Lancement des Services

1.  **Lancer le serveur MLflow** (souvent sur l'instance EC2, port `5000`) :

    ```bash
    mlflow server --host 0.0.0.0 --port 5000 --backend-store-uri $BACKEND_URI --default-artifact-root $ARTIFACT_URI
    ```

2.  **Lancer l'API FastAPI** (pour l'entra√Ænement et la pr√©diction, port `8001`) :

    ```bash
    python -m uvicorn api_pipeline:app --host 0.0.0.0 --port 8001 --reload
    ```

    *Note: L'API lance √©galement l'**Exporter Prometheus** sur le port `8000` via `aynid_pipeline.py`.*

3.  **Configurer Prometheus & Grafana** :

      * Le fichier `prometheus.yaml` doit pointer vers l'**adresse IP publique de l'instance EC2** h√©bergeant l'API sur le port `8000` (voir `scrape_configs`).
      * Importez le dashboard Grafana `aynid_ml_dashboard.json` et configurez une source de donn√©es Prometheus pointant vers votre serveur Prometheus.

4.  **Lancer le tableau de bord Streamlit** (depuis votre machine locale, si l'API est accessible) :

    ```bash
    streamlit run streamlit_app.py
    ```

      * **Attention** : Mettez √† jour `API_URL` dans `streamlit_app.py` avec l'IP publique de votre instance EC2 si l'API n'est pas locale.

-----

### üíª Utilisation des Composants Cl√©s

#### üìä Pipeline ML (`aynid_pipeline.py` / `mlflow_aws.py`)

Ce module g√®re le cycle de vie ML complet :

  * **Connexion aux Services :** S3 (artefacts), PostgreSQL (m√©triques personnalis√©es), MLflow (tracking).
  * **Pr√©paration des donn√©es :** G√©n√®re des donn√©es synth√©tiques pour la pr√©diction d'abandon de panier.
  * **Entra√Ænement du mod√®le :** Utilise un **RandomForestClassifier**.
  * **Tracking MLflow :** Log des param√®tres, m√©triques et du mod√®le.
  * **Monitoring Prometheus :** Met √† jour les m√©triques expos√©es sur le port `8000` (Accuracy, F1-Score, etc.).
  * **Persistance des M√©triques :** Sauvegarde des m√©triques cl√©s dans une table **PostgreSQL** (`custom_metrics`).

#### üåê API FastAPI (`api_pipeline.py`)

L'API expose trois endpoints principaux :

| Endpoint | M√©thode | Description | Payload (Exemple) |
| :--- | :--- | :--- | :--- |
| `/` | `GET` | Message de bienvenue. | - |
| `/train` | `POST` | Lance la pr√©paration des donn√©es et l'entra√Ænement du mod√®le. Sauvegarde le mod√®le localement (`model_latest.pkl`). | `{"n_samples": 5000}` |
| `/predict` | `POST` | Effectue une pr√©diction en utilisant `model_latest.pkl`. | `{"session_duration": 350.0, "pages_visited": 8, "cart_value": 75.0, "time_of_day": 14, "device_mobile": 1, "user_returning": 1, "items_in_cart": 3}` |
| `/metrics`| `GET` | Affiche un message de statut pour le monitoring Prometheus. | - |

#### üìà Dashboard Streamlit (`streamlit_app.py`)

Une interface simple pour :

1.  **Lancer un nouvel entra√Ænement** via l'endpoint `/train` de l'API.
2.  **Visualiser** les m√©triques et des extraits des jeux de donn√©es g√©n√©r√©s.
3.  **Tester la pr√©diction** pour un utilisateur donn√© via l'endpoint `/predict`.

-----

### ‚òÅÔ∏è Configuration AWS

Le pipeline n√©cessite :

1.  Un **bucket S3** (`mlflow-artefacts-aynid`) pour stocker les artefacts MLflow (mod√®les, m√©triques CSV, plots).
2.  Une base de donn√©es **PostgreSQL RDS** (ou compatible) pour le *backend* de suivi MLflow et pour stocker les m√©triques personnalis√©es du pipeline (`custom_metrics`).

Les informations de connexion √† ces services sont g√©r√©es via les variables d'environnement dans `mlflow_cg.sh` et utilis√©es par `aynid_pipeline.py` pour configurer MLflow.

-----

### üìà Observabilit√©

Le monitoring des performances du mod√®le est crucial :

  * **Prometheus Exporter (via `aynid_pipeline.py`):** Expose les m√©triques temps r√©el du dernier entra√Ænement (`model_accuracy`, `model_f1_score`, etc.) sur le port `8000`.
  * **Prometheus (configur√© via `prometheus.yaml`):** Scrape les m√©triques de l'API ML sur le port `8000` de l'instance EC2.
  * **Grafana (`aynid_ml_dashboard.json`):** Affiche les m√©triques collect√©es par Prometheus pour le suivi de la sant√© et de la performance du mod√®le.